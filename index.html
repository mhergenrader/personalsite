<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Michael Hergenrader</title>
	<meta name="description" content="Michael (Mike) Hergenrader is a Technical Program Manager for Google's Search Quality and Knowledge Graph capacity, with personal long-term research interests in neural model architectures and their applications to natural language tasks.">
	<meta name="author" content="Michael Hergenrader">
	<meta name="keywords" content="Michael Mike Hergenrader Computer Science USC Stanford Neural Networks Deep Learning NLP Research HCP">
	
	
	<link href="assets/css/bootstrap.css" rel="stylesheet">
	<style>
	  footer {
		text-align: center;
	  }
	  .profile {
		padding-bottom: 10px;
		display: block;
		margin: 0 auto;
	  }
	  .nolist {
		list-style: none;
	  }
	  .highlights {
		/*display: block;*/
		/*padding-left: 15px;*/
		padding-right: 15px;
		/*margin: 0 auto;
		max-width: 100%;*/
	  }
	  .about-list-header-nav {
		font-weight: bold;
	  }
	  .navbar .brand {
		color: #DDDDDD;
	  }
	  .phead {
		margin-bottom: 0;
		font-weight: bold;
	  }
	  #title {
		margin-bottom: 0;
	  }
	
    </style>
    <link href="assets/css/bootstrap-responsive.css" rel="stylesheet">
	
	<!--[if lt IE 9]>
		<script src="../assets/js/html5shiv.js"></script>
	<![endif]-->
	
</head>
<body>
	<div class="navbar navbar-inverse navbar-fixed-top">
		<div class="navbar-inner">
			<div class="container-fluid">
				<button type="button" class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a class="brand" href="#">Mike Hergenrader</a>
				<div class="nav-collapse collapse">
					<ul class="nav">
						<li class="active"><a href="#">About</a></li>
						<li><a href="uploads/resume.pdf">Resume (PDF)</a></li>
						<li><a href="research.html">Research</a></li>
						<li><a href="projects.html">Projects</a></li>
						<li><a href="personal.html">Personal</a></li>
					</ul>
				</div>
			</div>
		</div>
	</div>
	<div class="container-fluid">
		<div class="row-fluid">
			<div class="span3">
				<div class="well sidebar-nav">
					<img class="profile" src="uploads/profile.jpg" alt="Mike Hergenrader">
					<div class="highlights">
						<p class="phead">Michael (Mike) Hergenrader</p>
						<p><em>ˈmaɪkəl (maɪk) ˈhərgɛnreɪdər</em></p>
						<p class="phead">Current Position</p>
						<p id="title">Technical Program Manager, Google</p>
						<p><em>Search Quality, Knowledge Graph Capacity Planning</em></p>
						<p class="phead">Contact Me</p>
						<p>Please see my <a href="uploads/resume.pdf">resume</a>.</p>
					</div>
				</div>
			</div>
			<div class="span9">
				<div class="row-fluid">
					<h1>About Mike Hergenrader</h1>
					<ul>
						<li><a href="#goals">Goals</a></li>
						<li><a href="#research-interests">Research Interests</a></li>
						<li><a href="#awards">Awards &amp; Honors</a> <em>(updated Jan 1, 2016)</em></li>
					</ul>

					<hr>

					<h2><a id="goals">Goals</a></h2>
					<p>I have always had an aptitude and fascination for human languages, studying English, Spanish, Portuguese, Chinese, German, Greek, Catalan, and Italian in depth at different points in my life. Also piquing my interest has been the increasing ability of machine learning algorithms to help us better understand languages at scale and accomplish difficult high-level human tasks like translation, reading, speech recognition, generation, dialogue parsing, question-answering, and more.</p>
					
					<p>I want to understand in depth how machine learning methods can work so well with natural language tasks. I want to advance these methods to better our usage, understanding, and applications of language. <strong>To address these curiosities and goals, I am working toward a long-term career in machine learning and natural language processing research</strong>. As I next step, I aim to build a deeper, more theoretical background in this space to prepare me for a Ph.D. program.</p>
					
					<p>To this end, I am applying to Stanford's Master's in Computer Science program (through the <a href="https://web.stanford.edu/dept/registrar/bulletin1112/4832.htm">HCP</a> program), with a specialization in Artificial Intelligence, intending to enter in the Autumn 2016 quarter. I believe this program will not only help me to develop a formal understanding of machine learning and NLP (<a href="https://docs.google.com/spreadsheets/d/13IN1gbwUjA-o7iZiIOibrUrAP_KO9NQpujFXY6gndj8/edit#gid=0">my potential course plan</a> to this end) but also provide me with unique opportunities to contribute to groundbreaking research in these areas.</p>					
					
					<hr>
					
					<h2><a id="research-interests">Research Interests</a></h2>
					
					<p>My current primary interest - among others - lies in <strong>neural and deep sequence models</strong> like recurrent and recursive neural networks. I’m awestruck by the their ability to represent complex, variable-length sequences of correlated inputs - structures inherent to natural languages - in compact vectors. Moreover, the capability of deeper networks to uncover useful higher-level sequence features is an exciting opportunity to help us better understand human languages.</p>
						
					<p>With the goal of improving sequence learning tasks like <strong>Machine Reading and Machine Translation</strong>, I want to research architectures and methods that address the vanishing gradient problem that occurs in training deep neural and sequence models, allowing models to better capture correlations between inputs separated by long distances. In particular, I aim to explore and develop variants of gating mechanisms, like Long Short-term Memory and Gated Recurrent Units; attention mechanisms; and newer external memory-based architectures like Memory Networks, of <a href="http://arxiv.org/abs/1410.3916">Weston et al., 2015</a>, and Neural Turing Machines, of <a href="http://arxiv.org/abs/1410.5401">Graves et al., 2014</a>.</p>
					
					<p>After Professor Chris Manning first sparked my interest in these models in <a href="http://web.stanford.edu/class/cs276/">CS 276</a>, I spent the summer of 2015 building up a good understanding of the various model architectures and methods out there. During this time, I took Geoffrey Hinton's Neural Networks course via Coursera, and though I was not able to officially join the Neural Networks pilot course offered by the Google Brain team, I completed it as a self-study. My most recent course, <a href="http://web.stanford.edu/class/cs224n/">CS 224n</a>, solidified my interest in improving sequence model training for higher-level tasks of long inputs. It also exposed me to Stanford's innovative contributions to this class of models.</p>
					
					<p>Longer term at Stanford, I want to contribute to the research and advancement of these model architectures, working in the <a href="http://nlp.stanford.edu/">NLP Group</a> and pursuing a Distinction in Research.</p>
					
					<hr>
					
					<h2><a id="awards">Awards &amp; Honors</a></h2>
					<ul>
						<li><em>Outstanding Undergraduate Student in Computer Science</em> – highest department award given to one graduating senior majoring in
						 Computer Science at USC: selected by faculty for outstanding scholarship, research, or service</li>
						<li><em>Outstanding Undergraduate Student in Spanish/Portuguese</em> – highest department award given to one graduating senior majoring in
						 Spanish at USC: selected by faculty for high academic achievement and significant contributions to the department</li>
						<li><em>Renaissance Scholar</em> – one of 172 USC graduating students with a 3.5+ GPA in two distinct fields of study</li>
						<li><em>Presidential Scholar</em> – four-year half-tuition merit-based scholarship to USC</li>
						<li><em>Thematic Option Honors Program</em> – completed USC honors general education track (&lt;200 freshmen accepted into program per year)</li>
						<li>Inducted as a junior at USC to Phi Beta Kappa (top 2% of entire class) and Phi Kappa Phi (top 7.5% of entire class) honor societies</li>
						<li>Named “best intern hire of 2011” by IBM Raleigh Extreme Blue management staff, based on technical contributions and soft skills</li>
						<li>Senior Capstone Project won <em>3rd place, Most Popular</em> awards (out of 12 capstone engineering projects) at USC Engineering Expo</li>
						<li><strong><em>NEW</em></strong> (January 1, 2016) <a href="projects.html#twilightlegion">Twilight Legion</a> has won <a href="http://www.ticalc.org/community/awards/poty/2015.html">ticalc.org's Program of the Year for 2015 (68k series)</a>, the most prestigious TI programming community award!</li>
					</ul>			
			
				</div>
			</div>
		</div>
	</div>
	<hr>
	<footer>
		<p>Copyright © 2015 - 2016 Michael Hergenrader</p>
		<small>Site powered by Bootstrap by Twitter</small>
	</footer>
	
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
	<script src="assets/js/bootstrap.min.js"></script>
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-68429174-1', 'auto');
	  ga('send', 'pageview');

	</script>
</body>
</html>